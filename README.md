# ACADZA Assignment â€“ AI Followâ€‘Up Assistant

An endâ€‘toâ€‘end **AI-powered follow-up question generator** built using **FastAPI, WebSockets, LangChain, Groq LLM, and Streamlit**.

The system takes a user's initial sentence and dynamically generates **three intelligent follow-up questions** in real time via a **WebSocket-based conversational flow**.

---

## ğŸ“Œ Features

* ğŸ”— **Real-time WebSocket communication** between frontend and backend
* ğŸ§  **LLM-powered follow-up question generation** using Groq (Qwen 32B)
* ğŸ”„ **Stateful multi-step conversation flow** (3 follow-ups)
* âš¡ **FastAPI backend** with clean modular design
* ğŸ¨ **Streamlit frontend** with chat-style UI
* ğŸ” Secure API key handling using `.env`

---

## ğŸ—ï¸ Project Structure

```
ACADZA-Assignment/
â”‚
â”œâ”€â”€ backend_src/
â”‚   â”œâ”€â”€ api.py              # FastAPI app + WebSocket logic
â”‚   â”œâ”€â”€ ai_factory.py       # Groq LLM initialization
â”‚   â”œâ”€â”€ follow_up.py        # Follow-up question generator logic
â”‚   â”œâ”€â”€ prompt.py           # LangChain prompt template
|   â”œâ”€â”€ requirements.txt    # Requirements for frontend to make api live
â”‚
â”œâ”€â”€ frontend_src/
â”‚   â””â”€â”€ app.py              # Streamlit frontend (WebSocket client)
â”‚
â”œâ”€â”€ config.py               # Environment & API key loader
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # API keys (not committed)
â””â”€â”€ README.md
```

---

## ğŸ§  AI Integration (LangChain + Groq)

* The LLM is initialized in **`ai_factory.py`** using `ChatGroq`
* Model used: **`qwen/qwen3-32b`**
* LangChain pipeline:

```
PromptTemplate â†’ Groq LLM â†’ Response Cleanup
```

### Prompt Rules

* Generate **ONLY ONE** follow-up question
* The question **must include one exact word** from the user's input
* Output must be natural, conversational, and clean

---

## ğŸ” WebSocket Conversation Flow

### Backend (`/ws` endpoint)

1. Client connects â†’ server sends welcome message
2. Client sends initial sentence
3. AI generates Follow-up #1
4. Client answers
5. AI generates Follow-up #2
6. Client answers
7. AI generates Follow-up #3
8. Client answers
9. Server responds with final acknowledgment

> Entire flow is handled **within a single WebSocket session**

---

## ğŸ¨ Frontend Flow (Streamlit)

* User enters an initial sentence
* Streamlit establishes WebSocket connection
* Messages are exchanged step-by-step
* Session state tracks conversation progress
* Clean chat-style UI with conversation history

---

## âš™ï¸ Setup Instructions (Local)

### 1ï¸âƒ£ Clone Repository

```
git clone https://github.com/your-username/acadza-assignment.git
cd acadza-assignment
```

### 2ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file:

```
groq_api_key=YOUR_GROQ_API_KEY
google_gemini_api_key=OPTIONAL
```

---

## â–¶ï¸ Run the Project Locally

### ğŸ”¹ Start Backend (FastAPI)

```
uvicorn backend_src.api:app --reload
```

Backend will run at:

```
http://localhost:8000
ws://localhost:8000/ws
```

---

### ğŸ”¹ Start Frontend (Streamlit)

```
streamlit run frontend_src/app.py
```

Frontend will open at:

```
http://localhost:8501
```

> Update WebSocket URL in `frontend_src/app.py` when running locally:

```
ws.connect("ws://localhost:8000/ws")
```

---

## ğŸŒ Production Deployment

* Backend deployed on **Render**
* Secure WebSocket endpoint:

```
wss://acadza-assignment-3.onrender.com/ws
```

Frontend connects directly to the live WebSocket server.

---

## ğŸ“¸ Screenshots 


1. **Frontend UI â€“ Initial Input Screen**
![alt text](image.png)


2. **AI Follow-up Question Display**
![alt text](image-1.png)


3. **Multi-step Conversation Flow**
![alt text](image-2.png)


4. **Final Completion Screen**
![alt text](image-3.png)

## ğŸ§ª Tech Stack

* **Backend:** FastAPI, WebSockets, Uvicorn
* **Frontend:** Streamlit
* **LLM:** Groq (Qwen 32B)
* **AI Orchestration:** LangChain
* **Environment:** Python 3.10+

---


